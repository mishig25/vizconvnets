import { AdagradOptimizer, AdamOptimizer, Optimizer as CoreOptimizer, RMSPropOptimizer, Scalar, SGDOptimizer } from '@tensorflow/tfjs-core';
import { ConfigDict, LayerVariable } from './types';
import { Constructor } from './utils/generic_utils';
export interface OptimizerConfig {
    clipnorm?: number;
    clipvalue?: number;
}
export declare abstract class LayersOptimizer {
    clipnorm: number;
    clipvalue: number;
    protected optimizer: CoreOptimizer;
    private readonly createdFromCoreOptimizer;
    constructor(config: OptimizerConfig | CoreOptimizer);
    protected abstract constructFromCoreOptimizer(optimizer: CoreOptimizer): void;
    protected abstract constructFromConfig(config: OptimizerConfig): void;
    getConfig(): ConfigDict;
    updateVariables(lossFn: () => Scalar, params: LayerVariable[]): Scalar;
    static fromConfig<T>(cls: Constructor<T>, config: ConfigDict): T;
}
export interface SGDConfig extends OptimizerConfig {
    lr?: number;
    momentum?: number;
    decay?: number;
    nesterov?: boolean;
}
export declare class SGD extends LayersOptimizer {
    lr: number;
    momentum: number;
    decay: number;
    nesterov: boolean;
    constructor(config: SGDConfig | SGDOptimizer);
    constructFromConfig(config: SGDConfig): void;
    protected constructFromCoreOptimizer(optimizer: CoreOptimizer): void;
    getConfig(): ConfigDict;
}
export interface AdamConfig extends OptimizerConfig {
    lr?: number;
    beta_1?: number;
    beta_2?: number;
    epsilon?: number;
    decay?: number;
    amsgrad?: boolean;
}
export declare class Adam extends LayersOptimizer {
    lr: number;
    beta1: number;
    beta2: number;
    decay: number;
    epsilon: number;
    amsgrad: boolean;
    constructor(config: AdamConfig | AdamOptimizer);
    constructFromConfig(config: AdamConfig): void;
    protected constructFromCoreOptimizer(optimizer: CoreOptimizer): void;
    getConfig(): ConfigDict;
}
export interface RMSPropConfig extends OptimizerConfig {
    lr?: number;
    rho?: number;
    epsilon?: number;
    decay?: number;
}
export declare class RMSProp extends LayersOptimizer {
    lr: number;
    rho: number;
    decay: number;
    iterations: number;
    epsilon: number;
    constructor(config: RMSPropConfig | RMSPropOptimizer);
    constructFromConfig(config: RMSPropConfig): void;
    protected constructFromCoreOptimizer(optimizer: CoreOptimizer): void;
    getConfig(): ConfigDict;
}
export interface AdagradConfig extends OptimizerConfig {
    lr?: number;
    epsilon?: number;
    decay?: number;
}
export declare class Adagrad extends LayersOptimizer {
    private lr;
    private epsilon;
    private decay;
    constructor(config: AdagradConfig | AdagradOptimizer);
    constructFromConfig(config: AdagradConfig): void;
    constructFromCoreOptimizer(optimizer: CoreOptimizer): void;
    getConfig(): ConfigDict;
}
export declare const adagrad: typeof Adagrad;
export declare const adam: typeof Adam;
export declare const rmsprop: typeof RMSProp;
export declare const sgd: typeof SGD;
export declare function get(identifier: string | CoreOptimizer): Constructor<LayersOptimizer>;
